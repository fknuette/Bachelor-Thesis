{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8be86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tasks = ['clean','fgsm','pgd','apgd','square']\n",
    "\n",
    "dataset = pd.read_csv('/pfs/work7/workspace/scratch/ma_fknuette-project_GRANDE/data/result/imageNet/dataGeneral.csv')\n",
    "dataset = dataset.drop(columns=['isomorphTo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d9ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Single Objectives\n",
    "for task in tasks:\n",
    "    dataset_task = dataset\n",
    "    dataset_task = dataset_task[[col for col in dataset_task.columns if col == task or col not in tasks]]\n",
    "    X = dataset_task.drop(columns=[task])\n",
    "    y = dataset_task[task]\n",
    "\n",
    "    # Split the dataset\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "    # To numpy\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_valid = X_valid.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_valid = y_valid.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "    # Create a folder for the task if it doesn't exist\n",
    "    task_folder = f\"./{task}\"\n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "    # Save numpy arrays to the folder\n",
    "    np.save(os.path.join(task_folder, \"N_train.npy\"), X_train)\n",
    "    np.save(os.path.join(task_folder, \"N_val.npy\"), X_valid)\n",
    "    np.save(os.path.join(task_folder, \"N_test.npy\"), X_test)\n",
    "    np.save(os.path.join(task_folder, \"y_train.npy\"), y_train)\n",
    "    np.save(os.path.join(task_folder, \"y_val.npy\"), y_valid)\n",
    "    np.save(os.path.join(task_folder, \"y_test.npy\"), y_test)\n",
    "    \n",
    "    # Create a dictionary with information about the dataset\n",
    "    info = {\n",
    "        \"task_type\": 'regression',\n",
    "        \"n_num_features\": 14,\n",
    "        \"n_cat_features\": 0,\n",
    "        \"train_size\": X_train.shape[0],\n",
    "        \"val_size\": X_valid.shape[0],\n",
    "        \"test_size\": X_test.shape[0],\n",
    "        \"num_feature_intro\": {\n",
    "            feature: feature for feature in X.columns\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the dictionary as a JSON file\n",
    "    with open(os.path.join(task_folder, \"info.json\"), \"w\") as f:\n",
    "        json.dump(info, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300c8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Objectives\n",
    "for attack in tasks:\n",
    "    if attack == 'clean':\n",
    "        continue  # Skip pairing clean with itself\n",
    "\n",
    "    # Create a new dataset for the multi-objective task\n",
    "    dataset_multi = dataset\n",
    "    dataset_multi = dataset_multi[[col for col in dataset_multi.columns if col in ['clean', attack] or col not in tasks]]\n",
    "    X = dataset_multi.drop(columns=['clean', attack])\n",
    "    y = dataset_multi[['clean', attack]]\n",
    "\n",
    "    # Split the dataset\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "    # To numpy\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_valid = X_valid.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_valid = y_valid.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "    # Create a folder for the multi-objective task if it doesn't exist\n",
    "    task_folder = os.path.join(\"..\", \"multi\", f\"clean_{attack}\")\n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # Save numpy arrays to the folder\n",
    "    np.save(os.path.join(task_folder, \"N_train.npy\"), X_train)\n",
    "    np.save(os.path.join(task_folder, \"N_val.npy\"), X_valid)\n",
    "    np.save(os.path.join(task_folder, \"N_test.npy\"), X_test)\n",
    "    np.save(os.path.join(task_folder, \"y_train.npy\"), y_train)\n",
    "    np.save(os.path.join(task_folder, \"y_val.npy\"), y_valid)\n",
    "    np.save(os.path.join(task_folder, \"y_test.npy\"), y_test)\n",
    "    \n",
    "    # Create a dictionary with information about the dataset\n",
    "    info = {\n",
    "        \"task_type\": 'regression',\n",
    "        \"n_num_features\": 14,\n",
    "        \"n_cat_features\": 0,\n",
    "        \"train_size\": X_train.shape[0],\n",
    "        \"val_size\": X_valid.shape[0],\n",
    "        \"test_size\": X_test.shape[0],\n",
    "        \"num_feature_intro\": {\n",
    "            feature: feature for feature in X.columns\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the dictionary as a JSON file\n",
    "    with open(os.path.join(task_folder, \"info.json\"), \"w\") as f:\n",
    "        json.dump(info, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
